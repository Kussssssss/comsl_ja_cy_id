{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3870abab",
   "metadata": {},
   "source": [
    "# Kiểm tra và xóa các file audio không có trong validated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88c9a5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng dòng trong các file tsv:\n",
      "validated.tsv: 2882\n",
      "\n",
      "Số lượng audio trong folder clips: 2881\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# CONFIGURATION\n",
    "xx = \"id\" #params type:{str}\n",
    "dataset_path = \"indonesia_dataset\"\n",
    "ROOT = Path(r\"C:\\Users\\Admin\\PycharmProjects\\comsl_ja_cy_id\")\n",
    "DATA_PATH = os.path.join(ROOT, dataset_path)\n",
    "\n",
    "data_dir = DATA_PATH\n",
    "clips_dir = os.path.join(data_dir, \"clips\")\n",
    "\n",
    "tsv_files = [\n",
    "    \"validated.tsv\"\n",
    "]\n",
    "\n",
    "print(\"Số lượng dòng trong các file tsv:\")\n",
    "for tsv_file in tsv_files:\n",
    "    tsv_path = os.path.join(data_dir, tsv_file)  \n",
    "    try:\n",
    "        with open(tsv_path, 'r', encoding='utf-8') as f:\n",
    "            line_count = sum(1 for line in f)\n",
    "        print(f\"{tsv_file}: {line_count}\")\n",
    "    except Exception as e:\n",
    "        print(f\"{tsv_file}: Lỗi - {e}\")\n",
    "\n",
    "audio_extensions = ('.mp3', '.wav', '.flac', '.ogg')\n",
    "audio_count = sum(1 for f in os.listdir(clips_dir) if f.lower().endswith(audio_extensions))\n",
    "print(f\"\\nSố lượng audio trong folder clips: {audio_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5676a4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng dòng trong các file tsv:\n",
      "covost_v2.cy_en.tsv: 47060\n"
     ]
    }
   ],
   "source": [
    "tsv_files = [\n",
    "    f\"covost_v2.{xx}_en.tsv\" # sửa path \n",
    "]\n",
    "\n",
    "print(\"Số lượng dòng trong các file tsv:\")\n",
    "for tsv_file in tsv_files:\n",
    "    tsv_path = os.path.join(data_dir, tsv_file)  \n",
    "    try:\n",
    "        with open(tsv_path, 'r', encoding='utf-8') as f:\n",
    "            line_count = sum(1 for line in f)\n",
    "        print(f\"{tsv_file}: {line_count}\")\n",
    "    except Exception as e:\n",
    "        print(f\"{tsv_file}: Lỗi - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8e6a63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã xoá 8642 file không có trong validated.tsv.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "data_dir = DATA_PATH\n",
    "clips_dir = os.path.join(data_dir, \"clips\")\n",
    "validated_tsv = os.path.join(data_dir, \"validated.tsv\")\n",
    "\n",
    "# Đọc tất cả path hợp lệ từ validated.tsv\n",
    "valid_paths = set()\n",
    "with open(validated_tsv, 'r', encoding='utf-8') as tsvfile:\n",
    "    reader = csv.DictReader(tsvfile, delimiter='\\t')\n",
    "    for row in reader:\n",
    "        valid_paths.add(row['path'])\n",
    "\n",
    "# Duyệt tất cả file trong clips, xoá file không có trong valid_paths\n",
    "deleted_count = 0\n",
    "for file_name in os.listdir(clips_dir):\n",
    "    if file_name not in valid_paths:\n",
    "        file_path = os.path.join(clips_dir, file_name)\n",
    "        try:\n",
    "            os.remove(file_path)\n",
    "            deleted_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi xoá {file_name}: {e}\")\n",
    "\n",
    "print(f\"Đã xoá {deleted_count} file không có trong validated.tsv.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0538f708",
   "metadata": {},
   "source": [
    "# Scale train/dev/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83ceaa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "TRAIN_PATH = os.path.join(ROOT, f\"{dataset_path}\", f\"covost_v2.{xx}_en.train.tsv\")\n",
    "DEV_PATH = os.path.join(ROOT, f\"{dataset_path}\", f\"covost_v2.{xx}_en.dev.tsv\")\n",
    "TEST_PATH = os.path.join(ROOT, f\"{dataset_path}\", f\"covost_v2.{xx}_en.test.tsv\")\n",
    "EXTRA_PATH = os.path.join(ROOT, f\"{dataset_path}\", 'psudo', f\"{xx}_en.train.tsv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4d3a54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã tạo file: C:\\Users\\Admin\\PycharmProjects\\comsl_ja_cy_id\\welsh_dataset\\covost_v2.cy_en.train.tsv với 1200 dòng\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1200"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsv_path = TRAIN_PATH\n",
    "df = pd.read_csv(tsv_path, sep=\"\\t\")\n",
    "\n",
    "# Giữ lại 1200 dòng đầu tiên\n",
    "train_df = df.head(1200)\n",
    "\n",
    "# Lưu ra file mới (ví dụ ở thư mục working, hoặc ghi đè nếu muốn)\n",
    "train_tsv_path = TRAIN_PATH\n",
    "train_df.to_csv(train_tsv_path, sep=\"\\t\", index=False)\n",
    "\n",
    "print(f\"Đã tạo file: {train_tsv_path} với {len(train_df)} dòng\")\n",
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "859f1ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã tạo file: C:\\Users\\Admin\\PycharmProjects\\comsl_ja_cy_id\\welsh_dataset\\covost_v2.cy_en.test.tsv với 150 dòng\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsv_path = TEST_PATH\n",
    "df = pd.read_csv(tsv_path, sep=\"\\t\")\n",
    "\n",
    "# Giữ lại 150 dòng đầu tiên\n",
    "test_df = df.head(150)\n",
    "\n",
    "test_tsv_path = TEST_PATH\n",
    "test_df.to_csv(test_tsv_path, sep=\"\\t\", index=False)\n",
    "\n",
    "print(f\"Đã tạo file: {test_tsv_path} với {len(test_df)} dòng\")\n",
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2405d8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã tạo file: C:\\Users\\Admin\\PycharmProjects\\comsl_ja_cy_id\\welsh_dataset\\covost_v2.cy_en.dev.tsv với 150 dòng\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsv_path = DEV_PATH\n",
    "df = pd.read_csv(tsv_path, sep=\"\\t\")\n",
    "\n",
    "# Giữ lại 150 dòng đầu tiên\n",
    "dev_df = df.head(150)\n",
    "\n",
    "# Lưu ra file mới (ví dụ ở thư mục working, hoặc ghi đè nếu muốn)\n",
    "dev_tsv_path = DEV_PATH\n",
    "dev_df.to_csv(dev_tsv_path, sep=\"\\t\", index=False)\n",
    "\n",
    "print(f\"Đã tạo file: {dev_tsv_path} với {len(dev_df)} dòng\")\n",
    "len(dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1eddb61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã tạo file: C:\\Users\\Admin\\PycharmProjects\\comsl_ja_cy_id\\indonesia_dataset\\psudo\\id_en.train.tsv với 120 dòng\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsv_path = EXTRA_PATH\n",
    "df = pd.read_csv(tsv_path, sep=\"\\t\")\n",
    "\n",
    "# Giữ lại 120 dòng đầu tiên\n",
    "extra_df = df.head(120)\n",
    "\n",
    "# Lưu ra file mới (ví dụ ở thư mục working, hoặc ghi đè nếu muốn)\n",
    "extra_tsv_path = EXTRA_PATH\n",
    "extra_df.to_csv(extra_tsv_path, sep=\"\\t\", index=False)\n",
    "\n",
    "print(f\"Đã tạo file: {extra_tsv_path} với {len(extra_df)} dòng\")\n",
    "len(extra_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61402050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved: common_voice_id_25361422.mp3\n",
      "Moved: common_voice_id_25377216.mp3\n",
      "Moved: common_voice_id_25378794.mp3\n",
      "Moved: common_voice_id_25378817.mp3\n",
      "Moved: common_voice_id_25436710.mp3\n",
      "Moved: common_voice_id_25449451.mp3\n",
      "Moved: common_voice_id_26208370.mp3\n",
      "Moved: common_voice_id_26208371.mp3\n",
      "Moved: common_voice_id_26208372.mp3\n",
      "Moved: common_voice_id_26208373.mp3\n",
      "Moved: common_voice_id_26208374.mp3\n",
      "Moved: common_voice_id_26208376.mp3\n",
      "Moved: common_voice_id_26208377.mp3\n",
      "Moved: common_voice_id_26208378.mp3\n",
      "Moved: common_voice_id_26208379.mp3\n",
      "Moved: common_voice_id_26208380.mp3\n",
      "Moved: common_voice_id_26208399.mp3\n",
      "Moved: common_voice_id_26208400.mp3\n",
      "Moved: common_voice_id_26208403.mp3\n",
      "Moved: common_voice_id_26208404.mp3\n",
      "Moved: common_voice_id_26208449.mp3\n",
      "Moved: common_voice_id_26208450.mp3\n",
      "Moved: common_voice_id_26208451.mp3\n",
      "Moved: common_voice_id_26208452.mp3\n",
      "Moved: common_voice_id_26208453.mp3\n",
      "Moved: common_voice_id_26208470.mp3\n",
      "Moved: common_voice_id_26208471.mp3\n",
      "Moved: common_voice_id_26208472.mp3\n",
      "Moved: common_voice_id_26208473.mp3\n",
      "Moved: common_voice_id_26208526.mp3\n",
      "Moved: common_voice_id_26208527.mp3\n",
      "Moved: common_voice_id_26208528.mp3\n",
      "Moved: common_voice_id_26208529.mp3\n",
      "Moved: common_voice_id_26208530.mp3\n",
      "Moved: common_voice_id_26208580.mp3\n",
      "Moved: common_voice_id_26208581.mp3\n",
      "Moved: common_voice_id_26208582.mp3\n",
      "Moved: common_voice_id_26208583.mp3\n",
      "Moved: common_voice_id_26208584.mp3\n",
      "Moved: common_voice_id_26208598.mp3\n",
      "Moved: common_voice_id_26208599.mp3\n",
      "Moved: common_voice_id_26208600.mp3\n",
      "Moved: common_voice_id_26208602.mp3\n",
      "Moved: common_voice_id_26208603.mp3\n",
      "Moved: common_voice_id_26208618.mp3\n",
      "Moved: common_voice_id_26208620.mp3\n",
      "Moved: common_voice_id_26208622.mp3\n",
      "Moved: common_voice_id_26208626.mp3\n",
      "Moved: common_voice_id_26208658.mp3\n",
      "Moved: common_voice_id_26208659.mp3\n",
      "Moved: common_voice_id_26212975.mp3\n",
      "Moved: common_voice_id_26212977.mp3\n",
      "Moved: common_voice_id_26212978.mp3\n",
      "Moved: common_voice_id_26212979.mp3\n",
      "Moved: common_voice_id_26212980.mp3\n",
      "Moved: common_voice_id_26212987.mp3\n",
      "Moved: common_voice_id_26212988.mp3\n",
      "Moved: common_voice_id_26212989.mp3\n",
      "Moved: common_voice_id_26212990.mp3\n",
      "Moved: common_voice_id_26212991.mp3\n",
      "Moved: common_voice_id_26213002.mp3\n",
      "Moved: common_voice_id_26213003.mp3\n",
      "Moved: common_voice_id_26213004.mp3\n",
      "Moved: common_voice_id_26213005.mp3\n",
      "Moved: common_voice_id_26213006.mp3\n",
      "Moved: common_voice_id_26213012.mp3\n",
      "Moved: common_voice_id_26213013.mp3\n",
      "Moved: common_voice_id_26213014.mp3\n",
      "Moved: common_voice_id_26213015.mp3\n",
      "Moved: common_voice_id_26213300.mp3\n",
      "Moved: common_voice_id_26213301.mp3\n",
      "Moved: common_voice_id_26213302.mp3\n",
      "Moved: common_voice_id_26213303.mp3\n",
      "Moved: common_voice_id_26213305.mp3\n",
      "Moved: common_voice_id_26213306.mp3\n",
      "Moved: common_voice_id_26213307.mp3\n",
      "Moved: common_voice_id_26213308.mp3\n",
      "Moved: common_voice_id_26213309.mp3\n",
      "Moved: common_voice_id_26213310.mp3\n",
      "Moved: common_voice_id_26213311.mp3\n",
      "Moved: common_voice_id_26213312.mp3\n",
      "Moved: common_voice_id_26213313.mp3\n",
      "Moved: common_voice_id_26213314.mp3\n",
      "Moved: common_voice_id_26213505.mp3\n",
      "Moved: common_voice_id_26213506.mp3\n",
      "Moved: common_voice_id_26213507.mp3\n",
      "Moved: common_voice_id_26213508.mp3\n",
      "Moved: common_voice_id_26213509.mp3\n",
      "Moved: common_voice_id_26213520.mp3\n",
      "Moved: common_voice_id_26213521.mp3\n",
      "Moved: common_voice_id_26213522.mp3\n",
      "Moved: common_voice_id_26213523.mp3\n",
      "Moved: common_voice_id_26213524.mp3\n",
      "Moved: common_voice_id_26240329.mp3\n",
      "Moved: common_voice_id_26240330.mp3\n",
      "Moved: common_voice_id_26240331.mp3\n",
      "Moved: common_voice_id_26240332.mp3\n",
      "Moved: common_voice_id_26240338.mp3\n",
      "Moved: common_voice_id_26240339.mp3\n",
      "Moved: common_voice_id_26240340.mp3\n",
      "Moved: common_voice_id_26240341.mp3\n",
      "Moved: common_voice_id_26240342.mp3\n",
      "Moved: common_voice_id_26240348.mp3\n",
      "Moved: common_voice_id_26240349.mp3\n",
      "Moved: common_voice_id_26240350.mp3\n",
      "Moved: common_voice_id_26240351.mp3\n",
      "Moved: common_voice_id_26240352.mp3\n",
      "Moved: common_voice_id_26240353.mp3\n",
      "Moved: common_voice_id_26240354.mp3\n",
      "Moved: common_voice_id_26240355.mp3\n",
      "Moved: common_voice_id_26240356.mp3\n",
      "Moved: common_voice_id_26240393.mp3\n",
      "Moved: common_voice_id_26240394.mp3\n",
      "Moved: common_voice_id_26240395.mp3\n",
      "Moved: common_voice_id_26240401.mp3\n",
      "Moved: common_voice_id_26240402.mp3\n",
      "Moved: common_voice_id_26240403.mp3\n",
      "Moved: common_voice_id_26240404.mp3\n",
      "Moved: common_voice_id_26240405.mp3\n",
      "Moved: common_voice_id_26240406.mp3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "# 1) Thiết lập đường dẫn\n",
    "tsv_file = EXTRA_PATH\n",
    "src_dir  = r\"C:\\Users\\Admin\\PycharmProjects\\comsl_ja_cy_id\\cv-corpus-11.0-2022-09-21-id\\cv-corpus-11.0-2022-09-21\\id\\clips\"\n",
    "dst_dir  = r\"C:\\Users\\Admin\\PycharmProjects\\comsl_ja_cy_id\\indonesia_dataset\\clips\"\n",
    "\n",
    "# 2) Tạo folder đích nếu chưa có\n",
    "os.makedirs(dst_dir, exist_ok=True)\n",
    "\n",
    "# 3) Đọc cột 'path' trong TSV (chỉ lấy tên file)\n",
    "df = pd.read_csv(tsv_file, sep='\\t', usecols=['path'])\n",
    "\n",
    "# 4) Duyệt qua danh sách file, move từng file\n",
    "for fname in df['path'].dropna().unique():\n",
    "    # chỉ lấy tên file (nếu TSV chứa đường dẫn tương đối)\n",
    "    filename = os.path.basename(fname)\n",
    "    src_path = os.path.join(src_dir, filename)\n",
    "    dst_path = os.path.join(dst_dir, filename)\n",
    "\n",
    "    if os.path.exists(src_path):\n",
    "        try:\n",
    "            shutil.move(src_path, dst_path)\n",
    "            print(f\"Moved: {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Lỗi khi move {filename}: {e}\")\n",
    "    else:\n",
    "        print(f\"❌ Không tìm thấy: {src_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30eecdbf",
   "metadata": {},
   "source": [
    "# Kaggle - Visualize "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0451f527",
   "metadata": {},
   "source": [
    "%pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8a2421",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for file in os.listdir(\"/kaggle/working/comsl/output/comsl_mn2en/logs/ComST/default\"):\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f880d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tất cả các scalar tag:\n",
      "['lr-AdamW/pg1', 'lr-AdamW/pg2', 'train_acc_asr', 'train_nll_loss_asr', 'train_acc_text_translate', 'train_nll_loss_text_translate', 'train_acc_speech_translate', 'train_nll_loss_speech_translate', 'train_acc_mix_speech_translate', 'train_nll_loss_mix_speech_translate', 'train_acc_mix_asr', 'train_nll_loss_mix_asr', 'train_acc_mix_mlm', 'train_nll_loss_mix_mlm', 'train_guide_loss', 'train_reg_loss', 'epoch', 'val_bleu_spch_epoch', 'val_bleu_text_epoch', 'val_wer_epoch', 'val_speech_nll_loss_epoch', 'val_speech_acc_epoch', 'val_asr_nll_loss_epoch', 'val_asr_acc_epoch', 'val_text_nll_loss_epoch', 'val_text_acc_epoch', 'val_mix_speech_nll_loss_epoch', 'val_mix_asr_nll_loss_epoch', 'val_mix_mlm_nll_loss_epoch', 'val_mix_speech_acc_epoch', 'val_mix_asr_acc_epoch', 'val_mix_mlm_acc_epoch', 'val_guide_loss_epoch', 'val_reg_loss_epoch']\n"
     ]
    }
   ],
   "source": [
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "import os\n",
    "\n",
    "event_path = r\"C:\\Users\\Admin\\PycharmProjects\\comsl_ja_cy_id\\events.out.tfevents.1748828774.5b6844db7a6f.133.0\"\n",
    "\n",
    "event_acc = EventAccumulator(event_path)\n",
    "event_acc.Reload()\n",
    "\n",
    "print(\"Tất cả các scalar tag:\")\n",
    "print(event_acc.Tags()['scalars'])  # In ra các metric mà bạn có thể đọc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf9ebf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /kaggle/working/comsl/output/comsl_mn2en/logs/ComST/default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f294166e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = event_acc.Scalars('train_acc_asr')\n",
    "train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eec358c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "steps = np.array([e.step for e in train_acc])\n",
    "values = np.array([e.value for e in train_acc])\n",
    "\n",
    "num_samples = 1200\n",
    "batch_size = 10 \n",
    "num_epochs = 5\n",
    "steps_per_epoch = int(np.ceil(num_samples / batch_size))\n",
    "\n",
    "# Map step sang epoch\n",
    "epoch_ids = (steps // steps_per_epoch).astype(int)   # epoch bắt đầu từ 0\n",
    "\n",
    "# Lưu trữ accuracy cho từng epoch\n",
    "epoch_acc_dict = {}\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_acc = values[epoch_ids == epoch]\n",
    "    if len(epoch_acc) > 0:\n",
    "        epoch_acc_dict[epoch+1] = epoch_acc.mean()  # lấy giá trị trung bình mỗi epoch\n",
    "    else:\n",
    "        epoch_acc_dict[epoch+1] = np.nan  # nếu epoch này chưa có dữ liệu\n",
    "\n",
    "# Convert về array để vẽ\n",
    "epochs = np.array(list(epoch_acc_dict.keys()))\n",
    "epoch_accs = np.array(list(epoch_acc_dict.values()))\n",
    "\n",
    "# Plot\n",
    "plt.plot(epochs, epoch_accs, marker='o')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Train Accuracy (%)\")\n",
    "plt.title(\"Train Accuracy per Epoch\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1881c59",
   "metadata": {},
   "source": [
    "# Kaggle - download checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1602dd7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
